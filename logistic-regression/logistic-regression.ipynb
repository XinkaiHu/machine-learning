{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaac248c-9232-488b-93b9-4b29e140feee",
   "metadata": {},
   "source": [
    "# 加载必要的工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecc9d19-05f2-470e-a4c1-5e4dc4463989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a4c10-39fe-48e0-8b09-15fb2175b5a5",
   "metadata": {},
   "source": [
    "# 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f28493f-ee5e-475a-8743-0d19917e4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file: str, sep: str = ' ') -> tuple:\n",
    "    \"\"\"\n",
    "    从文件中加载数据。要求数据文件每行包含一个样例且每行最后一个数据为样例标签。\n",
    "    input:\n",
    "        file: 数据文件路径。\n",
    "        sep: 文件中每个特征的分隔符。\n",
    "    output:\n",
    "        X: 每行表示一个样本、每列表示一个样本特征的矩阵。\n",
    "        Y: 每行表示一个样本标签、列数为 1 的向量。\n",
    "    \"\"\"\n",
    "    with open(file=file, mode='r') as f:\n",
    "        data = np.array([[\n",
    "            np.float64(feature)\n",
    "            for feature in sample.strip().split(sep=sep)]\n",
    "            for sample in f.readlines()])\n",
    "\n",
    "    X = data[:, :-1]\n",
    "    Y = data[:, -1]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ad611-569d-4f0f-aa18-252bd784404d",
   "metadata": {},
   "source": [
    "## 加载西瓜数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6e5a29-bdf4-4e3d-bdff-2077ab607929",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, Y_training = load_data('dataset/melon_training.txt', ',')\n",
    "X_test, Y_test = load_data('dataset/melon_test.txt', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3da34b-e8d9-42bc-a39e-71fdc8d49b1e",
   "metadata": {},
   "source": [
    "## 加载鸢尾花数据集\n",
    "由于鸢尾花有三个分类标签，分类的思路是：训练三个 logistic regression 模型，每个模型分别计算样本属于三个分类的概率，取三者中概率最大者的分类为样本的分类。\n",
    "\n",
    "加载数据时每个训练集、测试集把一个分类标签视作 1，其他两个分类标签视作 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f56d925-dfb3-4c05-aa01-a273b8e30c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X_training, iris_Y_training = load_data(\n",
    "    file='dataset/iris_training.txt', sep=',')\n",
    "iris_Y_training_0 = np.array(\n",
    "    [np.float64(1.) if y == 0. else np.float64(0.) for y in iris_Y_training])\n",
    "iris_Y_training_1 = np.array(\n",
    "    [np.float64(1.) if y == 1. else np.float64(0.) for y in iris_Y_training])\n",
    "iris_Y_training_2 = np.array(\n",
    "    [np.float64(1.) if y == 2. else np.float64(0.) for y in iris_Y_training])\n",
    "\n",
    "iris_X_test, iris_Y_test = load_data(file='dataset/iris_test.txt', sep=',')\n",
    "iris_Y_test_0 = np.array(\n",
    "    [np.float64(1.) if y == 0. else np.float64(0.) for y in iris_Y_test])\n",
    "iris_Y_test_1 = np.array(\n",
    "    [np.float64(1.) if y == 1. else np.float64(0.) for y in iris_Y_test])\n",
    "iris_Y_test_2 = np.array(\n",
    "    [np.float64(1.) if y == 2. else np.float64(0.) for y in iris_Y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd2185-4a2c-4d7a-8b84-2d282391790d",
   "metadata": {},
   "source": [
    "# 加载参数\n",
    "西瓜数据集的参数保存在 `./parameters.txt` 中。\n",
    "鸢尾花数据集的参数保存在 `./parameters_0.txt`、`./parameters_1.txt`、`./parameters_2.txt` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43f9300e-afe2-490b-8b1c-0bcfd85f88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(file: str) -> tuple:\n",
    "    \"\"\"\n",
    "    加载文件中的参数。\n",
    "    input:\n",
    "        file: 保留参数的文件路径。\n",
    "    output:\n",
    "        文件中保留的 weights 和 bias。\n",
    "    \"\"\"\n",
    "    with open(file=file, mode='r') as f:\n",
    "        para = f.readline().strip().split(',')\n",
    "        weights = np.array(para[:-1], dtype=np.float64)\n",
    "        bias = np.array(para[-1:], dtype=np.float64)\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef1848-14f5-4205-9883-d84355abcf83",
   "metadata": {},
   "source": [
    "## 西瓜数据集的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2316eb48-2bf9-42f0-afa0-72222487d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('parameters.txt'):\n",
    "    melon_weights, melon_bias = np.random.rand(2), np.random.rand(1)\n",
    "else:\n",
    "    melon_weights, melon_bias = load_parameters('parameters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e74f3-dab2-4895-a4d2-220f5a3aaca6",
   "metadata": {},
   "source": [
    "## 鸢尾花数据集的参数\n",
    "与鸢尾花的三个模型对应有三组参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8def0386-4711-4fc6-aa5c-903f15109b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('parameters_0.txt'):\n",
    "    weights_0, bias_0 = np.random.rand(4), np.random.rand(1)\n",
    "else:\n",
    "    weights_0, bias_0 = load_parameters('parameters_0.txt')\n",
    "if not os.path.exists('parameters_1.txt'):\n",
    "    weights_1, bias_1 = np.random.rand(4), np.random.rand(1)\n",
    "else:\n",
    "    weights_1, bias_1 = load_parameters('parameters_1.txt')\n",
    "if not os.path.exists('parameters_2.txt'):\n",
    "    weights_2, bias_2 = np.random.rand(4), np.random.rand(1)\n",
    "else:\n",
    "    weights_2, bias_2 = load_parameters('parameters_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ead55-82c7-443c-9feb-3d54afc4143f",
   "metadata": {},
   "source": [
    "# Sigmoid 函数\n",
    "$$\\operatorname{Sigmoid}\\left(z\\right) = \\frac{1}{1 + \\exp\\left(-z\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dacdf311-7252-42a1-b219-fb80f974f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Sigmoid(z) = 1 / (1 + exp(-z))。\n",
    "    \"\"\"\n",
    "    return np.float64(1.) / (np.float64(1.) + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff0352-1b43-4665-9e9e-33d687d488e7",
   "metadata": {},
   "source": [
    "# 预测分类\n",
    "$$P\\left(y=1\\right) = \\operatorname{Sigmoid}\\left(\\vec{w}^T\\cdot\\vec{x}+b\\right)$$\n",
    "$$P\\left(y=0\\right) = 1 - P\\left(y=1\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f62eb3e-2e0b-4b34-b9fb-16c78655081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: np.matrix, weights: np.array, bias: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    根据样本和权重预测样本的标签。\n",
    "    P{y = 1 | X} = sigmoid(w^T x + b)。\n",
    "    input:\n",
    "        X: 同 load_data 中的 X。\n",
    "        weights: 行数为样本特征数、列数为 1 的权重向量。即公式中的 w。\n",
    "        bias: 即公式中的 b。\n",
    "    output:\n",
    "        与 load_data 中 Y 形状相同、对 Y 的预测值。\n",
    "    \"\"\"\n",
    "    positive = sigmoid(np.dot(X, weights) + bias)\n",
    "    negative = 1 - positive\n",
    "    return np.argmax(np.array([negative, positive]), axis=0)\n",
    "\n",
    "\n",
    "def multi_predict(X: np.matrix, weights: np.matrix, bias: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    根据样本和权重预测样本的标签。\n",
    "    是 predict 针对多分类问题的改进。\n",
    "    假设共有 C 个类别、训练 C 个 logistic regression 模型、\n",
    "    预测时计算样本属于每个类的概率、取概率最大者作为样本的概率。\n",
    "    input:\n",
    "        X: 同 predict 中的 X。\n",
    "        weights: 与 predict 中的不同、此处 weights 有 C 行、每行对应 predict 中\n",
    "            一个 logistic regression 模型的 weights。\n",
    "        bias: 与 predict 中的不同。此处 bias 为 C 行 1 列的向量。\n",
    "    output:\n",
    "        与 load_data 中 Y 形状相同、对 Y 的预测值。\n",
    "    \"\"\"\n",
    "    pred = sigmoid(np.matmul(X, weights.T) +\n",
    "                   np.matmul(np.ones((X.shape[0], 1), dtype=np.float64), bias.T))\n",
    "    return np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce300d7e-a74c-4898-a64f-1140e4254891",
   "metadata": {},
   "source": [
    "# 损失函数\n",
    "单个训练样本的损失函数为$$L\\left(f\\left(x^{\\left(i\\right)}\\right),y^{\\left(i\\right)}\\right)=\\left\\{\\begin{align}-\\mathop{ln}\\left(f\\left(\\vec{x}^{\\left(i\\right)}\\right)\\right),y^{\\left(i\\right)}=1,\\\\-\\mathop{ln}\\left(1-f\\left(\\vec{x}^{\\left(i\\right)}\\right)\\right),y^{\\left(1\\right)}=0\\end{align}\\right.\\\\=-y^{\\left(i\\right)}\\mathop{ln}\\left(f\\left(x^{\\left(i\\right)}\\right)\\right)-\\left(1-y^{\\left(i\\right)}\\right)\\mathop{ln}\\left(1-f\\left(x^{\\left(i\\right)}\\right)\\right)$$\n",
    "数据集整体的损失函数为\n",
    "$$J\\left(\\vec{w},b\\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{L\\left(f\\left(\\vec{x}^{\\left(i\\right)}\\right),y^{\\left(i\\right)}\\right)}$$\n",
    "# 梯度下降法优化损失函数\n",
    "$$w_j:=w_j-\\alpha\\frac{\\partial}{\\partial{w_j}}J\\left(\\vec{w},b\\right)$$\n",
    "$$b:=b-\\alpha\\frac{\\partial}{\\partial{b}}J\\left(\\vec{w},b\\right)$$\n",
    "其中\n",
    "$$\\frac{\\partial}{\\partial{w_j}}J\\left(\\vec{w},b\\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{\\left(f\\left(\\vec{x}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right)x_j^{\\left(i\\right)}}$$\n",
    "$$\\frac{\\partial}{\\partial{b}}J\\left(\\vec{w},b\\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{\\left(f\\left(\\vec{x}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07a12b0-263a-4b64-b34c-6bd84358f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X: np.matrix, Y: np.array, weights: np.array, bias: np.array, lr: np.float64) -> None:\n",
    "    \"\"\"\n",
    "    采用梯度下降法优化损失函数。损失函数采用交叉熵损失、其公式为\n",
    "        loss = -y ln y - (1 - y) ln(1 - y)。\n",
    "    对应的参数更新公式为\n",
    "        w_j := w_j - alpha / m * sum_i ((yhat_i - y_i) * x_i_j)\n",
    "        b := b - alpha / m * sum_i (yhat_i - y_i)\n",
    "    input:\n",
    "        X: 同 load_data 中的 X。\n",
    "        Y: 同 load_data 中的 Y。\n",
    "        weights: 同 predict 中的 weights。\n",
    "        bias: 同 predict 中的 bias。\n",
    "        lr: 学习率。即公式中的 alpha\n",
    "    \"\"\"\n",
    "    predictions = sigmoid(np.dot(X, weights) + bias)\n",
    "    weights -= lr * np.dot(predictions - Y, X) / len(Y)\n",
    "    bias -= lr * np.dot(np.ones((1, len(Y)), dtype=np.float64),\n",
    "                        predictions - Y) / len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f28b90e-4c84-49a4-98c0-d9eb727137e4",
   "metadata": {},
   "source": [
    "# 训练模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c626a7-bc67-4187-b704-a33f377da93d",
   "metadata": {},
   "source": [
    "## 训练西瓜数据集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41f1479-7e04-4e88-adcb-42f2d2ef667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "epoch = 10000\n",
    "for _ in range(epoch):\n",
    "    gradient_descent(X=X_training, Y=Y_training, weights=melon_weights, bias=melon_bias, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a7855-91df-4f7a-bb48-cae8588a299d",
   "metadata": {},
   "source": [
    "## 训练鸢尾花数据集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9304f1-86a5-4949-bea1-6cb560a91d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "epoch = 10000\n",
    "for _ in range(epoch):\n",
    "    gradient_descent(X=iris_X_training, Y=iris_Y_training_0,\n",
    "                     weights=weights_0, bias=bias_0, lr=lr)\n",
    "    gradient_descent(X=iris_X_training, Y=iris_Y_training_1,\n",
    "                     weights=weights_1, bias=bias_1, lr=lr)\n",
    "    gradient_descent(X=iris_X_training, Y=iris_Y_training_2,\n",
    "                     weights=weights_2, bias=bias_2, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78080c92-3a03-4f57-aaad-42348c701696",
   "metadata": {},
   "source": [
    "# 对模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6125ea-0796-411b-82f9-c5019638b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X: np.matrix, Y: np.array, weights: np.array, bias: np.array) -> None:\n",
    "    \"\"\"\n",
    "    根据给定的测试集和模型参数、测试模型的正确率。\n",
    "    input:\n",
    "        X: 同 load_data 中的 X。\n",
    "        Y: 同 load_data 中的 Y。\n",
    "        weights: 同 predict 中的 weights。\n",
    "        bias: 同 predict 中的 bias。\n",
    "    \"\"\"\n",
    "    predictions = predict(X=X, weights=weights, bias=bias)\n",
    "    right = 0\n",
    "    error = 0\n",
    "    for i in range(len(Y)):\n",
    "        if predictions[i] == Y[i]:\n",
    "            right += 1\n",
    "        else:\n",
    "            error += 1\n",
    "    print(\"Right: {}, error: {}, right rate: {}\".format(\n",
    "        right, error, right / (right + error)))\n",
    "\n",
    "\n",
    "def multi_test(X: np.matrix, Y: np.array, weights: np.array, bias: np.array) -> None:\n",
    "    \"\"\"\n",
    "    根据给定的测试集和模型参数、测试模型的正确率。\n",
    "    是 test 针对多分类问题的改进。\n",
    "    input:\n",
    "        X: 同 load_data 中的 X。\n",
    "        Y: 同 load_data 中的 Y。\n",
    "        weights: 同 multi_predict 中的 weights。\n",
    "        bias: 同 multi_predict 中的 bias。\n",
    "    \"\"\"\n",
    "    predictions = multi_predict(X=X, weights=weights, bias=bias)\n",
    "    right = 0\n",
    "    error = 0\n",
    "    for i in range(len(Y)):\n",
    "        if predictions[i] == Y[i]:\n",
    "            right += 1\n",
    "        else:\n",
    "            error += 1\n",
    "    print(\"Right: {}, error: {}, right rate: {}\".format(\n",
    "        right, error, right / (right + error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a00624-55da-4fe0-8f33-ea5357f3ca8f",
   "metadata": {},
   "source": [
    "## 西瓜数据集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3126b23-44cd-4d40-89d1-c963adf8c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- My Logistic Regression ----\n",
      "Weights: \n",
      "[ 3.05101701 12.10187337]\n",
      "Bias: \n",
      "[-4.28504056]\n",
      "Right: 12, error: 5, right rate: 0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "print('---- My Logistic Regression ----\\nWeights: \\n{}\\nBias: \\n{}'.format(melon_weights, melon_bias))\n",
    "test(X=X_test, Y=Y_test, weights=melon_weights, bias=melon_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792261eb-e7e7-4437-9442-54bf5ea2f550",
   "metadata": {},
   "source": [
    "## 鸢尾花数据集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "220a0683-6216-4635-8a48-1b8d533809a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- My Multi-Class Logistic Regression ----\n",
      "Weights: \n",
      "[[ 1.0325552   3.07961647 -5.25003492 -2.15822665]\n",
      " [ 0.06411905 -2.96329357  0.99255406 -2.48007079]\n",
      " [-3.76936662 -4.93324282  6.19725336  9.36306581]]\n",
      "Bias: \n",
      "[[ 0.74913973]\n",
      " [ 6.75277965]\n",
      " [-8.46841086]]\n",
      "In training set:\n",
      "Right: 103, error: 2, right rate: 0.9809523809523809\n",
      "In test set:\n",
      "Right: 44, error: 1, right rate: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "weights = np.matrix([weights_0, weights_1, weights_2])\n",
    "bias = np.matrix([bias_0, bias_1, bias_2])\n",
    "print('---- My Multi-Class Logistic Regression ----\\nWeights: \\n{}\\nBias: \\n{}'.format(weights, bias))\n",
    "print('In training set:')\n",
    "multi_test(X=iris_X_training, Y=iris_Y_training, weights=weights, bias=bias)\n",
    "print('In test set:')\n",
    "multi_test(X=iris_X_test, Y=iris_Y_test, weights=weights, bias=bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b6a93-b76a-4a62-ae51-051a5c552240",
   "metadata": {},
   "source": [
    "# 保存参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f090dcee-5c5a-4b5a-93a5-6d2bb22deedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parameters(file: str, weights: np.array, bias: np.array) -> None:\n",
    "    \"\"\"\n",
    "    将参数保留到文件中。\n",
    "    input:\n",
    "        file: 保留参数的文件路径。\n",
    "        weights: 同 predict 中的 weights。\n",
    "        bias: 同 predict 中的 bias。\n",
    "    \"\"\"\n",
    "    with open(file=file, mode='w') as f:\n",
    "        for w in weights:\n",
    "            f.write('{},'.format(w))\n",
    "        f.write('{}'.format(bias[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d8c568b-0ee6-4684-abbe-542a6ed044a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_parameters('parameters.txt', weights=melon_weights, bias=melon_bias)\n",
    "\n",
    "save_parameters('parameters_0.txt', weights=weights_0, bias=bias_0)\n",
    "save_parameters('parameters_1.txt', weights=weights_1, bias=bias_1)\n",
    "save_parameters('parameters_2.txt', weights=weights_2, bias=bias_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
