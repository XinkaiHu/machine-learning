{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_size\": 150,\n",
    "    \"train_size\": 120,\n",
    "    \"test_size\": 30,\n",
    "    \"feature_number\": 4,\n",
    "    \"num_class\": 3,\n",
    "    \"batch_size\": 30,\n",
    "    \"save_checkpoint_steps\": 5,\n",
    "    \"keep_checkpoint_max\": 1,\n",
    "    \"out_dir_no_opt\": os.path.join(\".\", \"model_iris\", \"no_opt\"),\n",
    "    \"out_dir_sgd\": os.path.join(\".\", \"model_iris\", \"sgd\"),\n",
    "    \"out_dir_momentum\": os.path.join(\".\", \"model_iris\", \"momentum\"),\n",
    "    \"out_dir_adam\": os.path.join(\".\", \"model_iris\", \"adam\"),\n",
    "    \"out_dir_prefix\": \"checkpoint_fashion_forward\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 5)\n",
    "        self.fc2 = nn.Linear(5, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义自己编写的优化器兼容 PyTorch 接口"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 无优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoOptimizer(optim.Optimizer):\n",
    "    def __init__(self, params, default={}) -> None:\n",
    "        super().__init__(params, default)\n",
    "        self.param_groups = params\n",
    "\n",
    "    def step(self):\n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySGD(optim.Optimizer):\n",
    "    def __init__(self, params, lr, default={}) -> None:\n",
    "        super().__init__(params, default)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param_group in self.param_groups:\n",
    "            params = param_group[\"params\"]\n",
    "            for param in params:\n",
    "                param.data -= self.lr * param.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentum(optim.Optimizer):\n",
    "    def __init__(self, params, lr, momentum, default={}) -> None:\n",
    "        super().__init__(params, default)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = []\n",
    "        for param_group in self.param_groups:\n",
    "            params = param_group[\"params\"]\n",
    "            self.v.append([torch.zeros_like(param.data) for param in params])\n",
    "\n",
    "    def step(self):\n",
    "        for i, param_group in enumerate(self.param_groups):\n",
    "            params = param_group[\"params\"]\n",
    "            v = self.v[i]\n",
    "            for j, param in enumerate(params):\n",
    "                v[j] = self.momentum * v[j] - self.lr * param.grad\n",
    "                param.data += v[j]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAdam(optim.Optimizer):\n",
    "    def __init__(self, params, lr, beta1, beta2, epsilon, default={}) -> None:\n",
    "        super().__init__(params, default)\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.v = []\n",
    "        self.m = []\n",
    "        for param_group in self.param_groups:\n",
    "            params = param_group[\"params\"]\n",
    "            self.v.append([torch.zeros_like(param.data) for param in params])\n",
    "            self.m.append([torch.zeros_like(param.data) for param in params])\n",
    "\n",
    "    def step(self):\n",
    "        for i, param_group in enumerate(self.param_groups):\n",
    "            params = param_group[\"params\"]\n",
    "            m = self.m[i]\n",
    "            v = self.v[i]\n",
    "            for j, param in enumerate(params):\n",
    "                m[j] = self.beta1 * m[j] + (1 - self.beta1) * param.grad\n",
    "                v[j] = self.beta2 * v[j] + (1 - self.beta2) * torch.square(param.grad)\n",
    "                param.data -= self.lr * m[j].div(self.epsilon + torch.sqrt(v[j]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义训练和测试过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, net, loss_fn, optimizer):\n",
    "    X_train, y_train = data\n",
    "    for batch in range(y_train.shape[0]):\n",
    "        pred = net(X_train[batch])\n",
    "        loss = loss_fn(pred, y_train[batch])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(data, net, loss_fn):\n",
    "    X_train, y_train = data\n",
    "    loss = 0\n",
    "    currect = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in range(y_train.shape[0]):\n",
    "            pred = net(X_train[batch])\n",
    "            loss += loss_fn(pred, y_train[batch])\n",
    "            if torch.argmax(pred) == y_train[batch]:\n",
    "                currect += 1\n",
    "    loss /= y_train.shape[0]\n",
    "    currect /= y_train.shape[0]\n",
    "    return loss, currect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "X_training, X_test, y_training, y_test = train_test_split(\n",
    "    iris_X, iris_y, test_size=config[\"test_size\"], train_size=config[\"train_size\"]\n",
    ")\n",
    "X_training = torch.tensor(X_training, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "y_training = torch.tensor(y_training, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化网络和损失函数\n",
    "初始化 7 个网络，用于对比分析不同优化器的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net0 = Net()\n",
    "net1 = Net()\n",
    "net2 = Net()\n",
    "net3 = Net()\n",
    "net4 = Net()\n",
    "net5 = Net()\n",
    "net6 = Net()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_optimizer = NoOptimizer(\n",
    "    params=net0.parameters(),\n",
    ")\n",
    "\n",
    "my_sgd = MySGD(\n",
    "    params=net1.parameters(),\n",
    "    lr=0.05,\n",
    ")\n",
    "\n",
    "sgd = optim.SGD(\n",
    "    params=net2.parameters(),\n",
    "    lr=0.05,\n",
    "    momentum=0.0,\n",
    ")\n",
    "\n",
    "my_momentum = MyMomentum(\n",
    "    params=net3.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    ")\n",
    "\n",
    "momentum = optim.SGD(\n",
    "    params=net4.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    ")\n",
    "\n",
    "my_adam = MyAdam(\n",
    "    params=net5.parameters(),\n",
    "    lr=0.001,\n",
    "    beta1=0.9,\n",
    "    beta2=0.99,\n",
    "    epsilon=1e-8,\n",
    ")\n",
    "\n",
    "adam = optim.Adam(\n",
    "    params=net6.parameters(),\n",
    "    lr=0.001,\n",
    "    betas=[\n",
    "        0.9,\n",
    "        0.99,\n",
    "    ],\n",
    "    eps=1e-8,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比较各优化器效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== No optimizer ===========\n",
      "Epoch 0:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 1:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 2:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 3:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 4:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 5:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 6:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 7:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 8:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 9:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 10:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 11:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 12:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 13:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 14:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 15:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 16:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 17:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 18:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n",
      "Epoch 19:\tLoss is 1.5873159170150757,\taccuracy is 0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== No optimizer ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net0,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=no_optimizer,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net0,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== My SGD ===========\n",
      "Epoch 0:\tLoss is 0.38999757170677185,\taccuracy is 0.7666666666666667\n",
      "Epoch 1:\tLoss is 0.3392419219017029,\taccuracy is 0.8\n",
      "Epoch 2:\tLoss is 0.3282116651535034,\taccuracy is 0.8\n",
      "Epoch 3:\tLoss is 0.32055795192718506,\taccuracy is 0.8\n",
      "Epoch 4:\tLoss is 0.30110231041908264,\taccuracy is 0.8333333333333334\n",
      "Epoch 5:\tLoss is 0.27049845457077026,\taccuracy is 0.8666666666666667\n",
      "Epoch 6:\tLoss is 0.24279597401618958,\taccuracy is 0.9\n",
      "Epoch 7:\tLoss is 0.22894611954689026,\taccuracy is 0.9\n",
      "Epoch 8:\tLoss is 0.2229236215353012,\taccuracy is 0.9\n",
      "Epoch 9:\tLoss is 0.2187321037054062,\taccuracy is 0.9\n",
      "Epoch 10:\tLoss is 0.2145044207572937,\taccuracy is 0.9\n",
      "Epoch 11:\tLoss is 0.21003161370754242,\taccuracy is 0.9\n",
      "Epoch 12:\tLoss is 0.20577366650104523,\taccuracy is 0.9333333333333333\n",
      "Epoch 13:\tLoss is 0.20219554007053375,\taccuracy is 0.9333333333333333\n",
      "Epoch 14:\tLoss is 0.19947503507137299,\taccuracy is 0.9333333333333333\n",
      "Epoch 15:\tLoss is 0.1976454257965088,\taccuracy is 0.9333333333333333\n",
      "Epoch 16:\tLoss is 0.19654807448387146,\taccuracy is 0.9333333333333333\n",
      "Epoch 17:\tLoss is 0.1955719292163849,\taccuracy is 0.9333333333333333\n",
      "Epoch 18:\tLoss is 0.19439463317394257,\taccuracy is 0.9333333333333333\n",
      "Epoch 19:\tLoss is 0.1943410336971283,\taccuracy is 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== My SGD ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net1,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=my_sgd,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net1,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== PyTorch SGD ===========\n",
      "Epoch 0:\tLoss is 0.3873150646686554,\taccuracy is 0.7333333333333333\n",
      "Epoch 1:\tLoss is 0.35090160369873047,\taccuracy is 0.7666666666666667\n",
      "Epoch 2:\tLoss is 0.3443080484867096,\taccuracy is 0.8\n",
      "Epoch 3:\tLoss is 0.33716824650764465,\taccuracy is 0.8\n",
      "Epoch 4:\tLoss is 0.31342145800590515,\taccuracy is 0.8333333333333334\n",
      "Epoch 5:\tLoss is 0.2778344452381134,\taccuracy is 0.8666666666666667\n",
      "Epoch 6:\tLoss is 0.24967060983181,\taccuracy is 0.8666666666666667\n",
      "Epoch 7:\tLoss is 0.23536576330661774,\taccuracy is 0.9\n",
      "Epoch 8:\tLoss is 0.22808484733104706,\taccuracy is 0.9\n",
      "Epoch 9:\tLoss is 0.22280992567539215,\taccuracy is 0.9\n",
      "Epoch 10:\tLoss is 0.21782471239566803,\taccuracy is 0.9\n",
      "Epoch 11:\tLoss is 0.21269993484020233,\taccuracy is 0.9\n",
      "Epoch 12:\tLoss is 0.20778529345989227,\taccuracy is 0.9333333333333333\n",
      "Epoch 13:\tLoss is 0.203510582447052,\taccuracy is 0.9333333333333333\n",
      "Epoch 14:\tLoss is 0.1999613493680954,\taccuracy is 0.9333333333333333\n",
      "Epoch 15:\tLoss is 0.19714969396591187,\taccuracy is 0.9333333333333333\n",
      "Epoch 16:\tLoss is 0.19527943432331085,\taccuracy is 0.9333333333333333\n",
      "Epoch 17:\tLoss is 0.19399107992649078,\taccuracy is 0.9333333333333333\n",
      "Epoch 18:\tLoss is 0.1934179961681366,\taccuracy is 0.9333333333333333\n",
      "Epoch 19:\tLoss is 0.19621329009532928,\taccuracy is 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== PyTorch SGD ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net2,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=sgd,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net2,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== My Momentum ===========\n",
      "Epoch 0:\tLoss is 0.3673272430896759,\taccuracy is 0.7333333333333333\n",
      "Epoch 1:\tLoss is 0.3536987900733948,\taccuracy is 0.8\n",
      "Epoch 2:\tLoss is 1.2589279413223267,\taccuracy is 0.7\n",
      "Epoch 3:\tLoss is 1.68669855594635,\taccuracy is 0.7\n",
      "Epoch 4:\tLoss is 0.3379596769809723,\taccuracy is 0.8333333333333334\n",
      "Epoch 5:\tLoss is 2.735685110092163,\taccuracy is 0.7\n",
      "Epoch 6:\tLoss is 0.22797778248786926,\taccuracy is 0.9333333333333333\n",
      "Epoch 7:\tLoss is 0.22898425161838531,\taccuracy is 0.9\n",
      "Epoch 8:\tLoss is 0.5694103240966797,\taccuracy is 0.7\n",
      "Epoch 9:\tLoss is 4.207204818725586,\taccuracy is 0.7\n",
      "Epoch 10:\tLoss is 0.16615407168865204,\taccuracy is 0.9\n",
      "Epoch 11:\tLoss is 0.18605954945087433,\taccuracy is 0.9333333333333333\n",
      "Epoch 12:\tLoss is 0.2255353182554245,\taccuracy is 0.9333333333333333\n",
      "Epoch 13:\tLoss is 0.20037534832954407,\taccuracy is 0.9\n",
      "Epoch 14:\tLoss is 2.0313522815704346,\taccuracy is 0.8\n",
      "Epoch 15:\tLoss is 3.411961078643799,\taccuracy is 0.7\n",
      "Epoch 16:\tLoss is 3.983588218688965,\taccuracy is 0.7\n",
      "Epoch 17:\tLoss is 0.2537359297275543,\taccuracy is 0.9\n",
      "Epoch 18:\tLoss is 0.6272057890892029,\taccuracy is 0.8333333333333334\n",
      "Epoch 19:\tLoss is 5.658889293670654,\taccuracy is 0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== My Momentum ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net3,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=my_momentum,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net3,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== PyTorch Momentum ===========\n",
      "Epoch 0:\tLoss is 0.7532129883766174,\taccuracy is 0.7\n",
      "Epoch 1:\tLoss is 1.0476608276367188,\taccuracy is 0.7\n",
      "Epoch 2:\tLoss is 0.21839022636413574,\taccuracy is 0.9333333333333333\n",
      "Epoch 3:\tLoss is 1.2472529411315918,\taccuracy is 0.7\n",
      "Epoch 4:\tLoss is 0.5363070368766785,\taccuracy is 0.7\n",
      "Epoch 5:\tLoss is 0.19136972725391388,\taccuracy is 0.9333333333333333\n",
      "Epoch 6:\tLoss is 0.23327694833278656,\taccuracy is 0.9333333333333333\n",
      "Epoch 7:\tLoss is 0.27730992436408997,\taccuracy is 0.9\n",
      "Epoch 8:\tLoss is 0.18601396679878235,\taccuracy is 0.9333333333333333\n",
      "Epoch 9:\tLoss is 0.23065759241580963,\taccuracy is 0.9333333333333333\n",
      "Epoch 10:\tLoss is 5.4513702392578125,\taccuracy is 0.7\n",
      "Epoch 11:\tLoss is 0.1767035275697708,\taccuracy is 0.9333333333333333\n",
      "Epoch 12:\tLoss is 0.18380142748355865,\taccuracy is 0.9\n",
      "Epoch 13:\tLoss is 0.17421826720237732,\taccuracy is 0.9333333333333333\n",
      "Epoch 14:\tLoss is 0.34657809138298035,\taccuracy is 0.9\n",
      "Epoch 15:\tLoss is 0.60945063829422,\taccuracy is 0.8333333333333334\n",
      "Epoch 16:\tLoss is 0.5316135883331299,\taccuracy is 0.8\n",
      "Epoch 17:\tLoss is 0.43165022134780884,\taccuracy is 0.9\n",
      "Epoch 18:\tLoss is 4.196465015411377,\taccuracy is 0.7\n",
      "Epoch 19:\tLoss is 1.0838302373886108,\taccuracy is 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== PyTorch Momentum ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net4,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=momentum,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net4,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== My Adam ===========\n",
      "Epoch 0:\tLoss is 1.0053554773330688,\taccuracy is 0.36666666666666664\n",
      "Epoch 1:\tLoss is 0.9487549662590027,\taccuracy is 0.5\n",
      "Epoch 2:\tLoss is 0.8877555131912231,\taccuracy is 0.7666666666666667\n",
      "Epoch 3:\tLoss is 0.8264539837837219,\taccuracy is 0.8333333333333334\n",
      "Epoch 4:\tLoss is 0.7664218544960022,\taccuracy is 0.8333333333333334\n",
      "Epoch 5:\tLoss is 0.7091507315635681,\taccuracy is 0.8333333333333334\n",
      "Epoch 6:\tLoss is 0.6560317873954773,\taccuracy is 0.8333333333333334\n",
      "Epoch 7:\tLoss is 0.6080805063247681,\taccuracy is 0.9\n",
      "Epoch 8:\tLoss is 0.5657724738121033,\taccuracy is 0.9\n",
      "Epoch 9:\tLoss is 0.5290507674217224,\taccuracy is 0.9333333333333333\n",
      "Epoch 10:\tLoss is 0.4974624216556549,\taccuracy is 0.9333333333333333\n",
      "Epoch 11:\tLoss is 0.4703356921672821,\taccuracy is 0.9333333333333333\n",
      "Epoch 12:\tLoss is 0.4469342529773712,\taccuracy is 0.9666666666666667\n",
      "Epoch 13:\tLoss is 0.42656150460243225,\taccuracy is 0.9666666666666667\n",
      "Epoch 14:\tLoss is 0.40861520171165466,\taccuracy is 0.9666666666666667\n",
      "Epoch 15:\tLoss is 0.39259928464889526,\taccuracy is 0.9666666666666667\n",
      "Epoch 16:\tLoss is 0.37810182571411133,\taccuracy is 0.9333333333333333\n",
      "Epoch 17:\tLoss is 0.3647744059562683,\taccuracy is 0.9333333333333333\n",
      "Epoch 18:\tLoss is 0.3523792028427124,\taccuracy is 0.9333333333333333\n",
      "Epoch 19:\tLoss is 0.3408193588256836,\taccuracy is 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== My Adam ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net5,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=my_adam,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net5,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== PyTorch Adam ===========\n",
      "Epoch 0:\tLoss is 0.9706352949142456,\taccuracy is 0.36666666666666664\n",
      "Epoch 1:\tLoss is 0.8454355597496033,\taccuracy is 0.9666666666666667\n",
      "Epoch 2:\tLoss is 0.7459096908569336,\taccuracy is 0.8333333333333334\n",
      "Epoch 3:\tLoss is 0.6582104563713074,\taccuracy is 0.8333333333333334\n",
      "Epoch 4:\tLoss is 0.5847419500350952,\taccuracy is 0.8666666666666667\n",
      "Epoch 5:\tLoss is 0.5261387825012207,\taccuracy is 0.9\n",
      "Epoch 6:\tLoss is 0.48016396164894104,\taccuracy is 0.9666666666666667\n",
      "Epoch 7:\tLoss is 0.44390174746513367,\taccuracy is 0.9666666666666667\n",
      "Epoch 8:\tLoss is 0.41469794511795044,\taccuracy is 0.9666666666666667\n",
      "Epoch 9:\tLoss is 0.39045223593711853,\taccuracy is 0.9666666666666667\n",
      "Epoch 10:\tLoss is 0.3696424067020416,\taccuracy is 0.9666666666666667\n",
      "Epoch 11:\tLoss is 0.35124650597572327,\taccuracy is 0.9666666666666667\n",
      "Epoch 12:\tLoss is 0.33463895320892334,\taccuracy is 0.9666666666666667\n",
      "Epoch 13:\tLoss is 0.319449782371521,\taccuracy is 0.9666666666666667\n",
      "Epoch 14:\tLoss is 0.3054209351539612,\taccuracy is 0.9333333333333333\n",
      "Epoch 15:\tLoss is 0.2923460304737091,\taccuracy is 0.9333333333333333\n",
      "Epoch 16:\tLoss is 0.2800789475440979,\taccuracy is 0.9333333333333333\n",
      "Epoch 17:\tLoss is 0.26857414841651917,\taccuracy is 0.9333333333333333\n",
      "Epoch 18:\tLoss is 0.2578541338443756,\taccuracy is 0.9333333333333333\n",
      "Epoch 19:\tLoss is 0.2479109764099121,\taccuracy is 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"=========== PyTorch Adam ===========\")\n",
    "for _ in range(epoch):\n",
    "    train(\n",
    "        data=(X_training, y_training),\n",
    "        net=net6,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=adam,\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = test(\n",
    "        data=(X_test, y_test),\n",
    "        net=net6,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    print(\"Epoch {}:\\tLoss is {},\\taccuracy is {}\".format(_, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
